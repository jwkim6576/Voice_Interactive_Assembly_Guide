import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import String, Float32MultiArray
from cv_bridge import CvBridge
import cv2
import numpy as np
import math
import json
from collections import deque  # [NEW] 3í”„ë ˆì„ ì €ì¥ì„ ìœ„í•œ í
from ultralytics import YOLO
from rclpy.qos import qos_profile_sensor_data

class YoloNode(Node):
    def __init__(self):
        super().__init__('yolo_node')
        
        try:
            self.model = YOLO(r'/home/rokey/ros2_ws/src/Tutorial/Calibration_Tutorial/data/please/rokey_obb_project/run_1/weights/best.pt', task='obb')
        except Exception as e:
            self.get_logger().error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e

        self.result_publisher = self.create_publisher(String, '/yolo_results', 10)
        self.pose_publisher = self.create_publisher(Float32MultiArray, '/yolo_object_pos', 10)
        self.all_objects_publisher = self.create_publisher(String, '/yolo_all_detect', 10)
        
        self.create_subscription(String, '/part_n_bad_dispose', self.command_callback, 10)
        self.create_subscription(String, '/part_n_bad_show', self.command_callback, 10)
        self.create_subscription(String, '/target_update', self.command_callback, 10)

        self.sub_color = self.create_subscription(
            Image, '/camera/camera/color/image_raw', self.image_callback, qos_profile_sensor_data)
        self.sub_depth = self.create_subscription(
            Image, '/camera/camera/aligned_depth_to_color/image_raw', self.depth_callback, qos_profile_sensor_data)
        self.sub_info = self.create_subscription(
            CameraInfo, '/camera/camera/aligned_depth_to_color/camera_info', self.info_callback, qos_profile_sensor_data)
        
        self.bridge = CvBridge()
        self.depth_image = None
        self.fx = 605.0; self.fy = 605.0; self.cx = 320.0; self.cy = 240.0
        self.is_intrinsics_received = False
        
        self.target_object = "part_1_bad"
        
        # [NEW] ë¬¼ì²´ë³„ë¡œ ìµœê·¼ 3í”„ë ˆì„ì˜ Depth í‰ê· ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        # êµ¬ì¡°: {'part_1_bad': deque([z1, z2, z3], maxlen=3), ...}
        self.depth_buffers = {}
        
        self.get_logger().info("âœ… YOLO Node v8 Ready (5-Point Spatial & 3-Frame Temporal Average)")

    def command_callback(self, msg):
        self.target_object = msg.data
        self.get_logger().info(f"ğŸ¯ íƒ€ê²Ÿ ë³€ê²½ë¨: {self.target_object}")

    def info_callback(self, msg):
        if not self.is_intrinsics_received:
            self.fx = msg.k[0]; self.cx = msg.k[2]
            self.fy = msg.k[4]; self.cy = msg.k[5]
            self.is_intrinsics_received = True

    def depth_callback(self, msg):
        try:
            self.depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except: pass

    # [ìˆ˜ì •] ì¢Œí‘œë§Œ ê³„ì‚°í•´ì„œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ê·¸ë¦¬ê¸°ìš©)
    def calculate_axis_points(self, cx, cy, length, angle_rad):
        dx = (length / 2) * math.cos(angle_rad)
        dy = (length / 2) * math.sin(angle_rad)
        p1 = (int(cx + dx), int(cy + dy))
        p2 = (int(cx - dx), int(cy - dy))
        return p1, p2

    # [NEW] íŠ¹ì • (u,v) ì¢Œí‘œì˜ ê¹Šì´ê°’ í•˜ë‚˜ë§Œ ì™ ë¹¼ì˜¤ëŠ” í•¨ìˆ˜
    def get_pixel_depth(self, u, v):
        if self.depth_image is None: return None
        h, w = self.depth_image.shape
        
        # ì´ë¯¸ì§€ ë²”ìœ„ ë²—ì–´ë‚˜ë©´ ë¬´ì‹œ
        if u < 0 or u >= w or v < 0 or v >= h: return None
        
        # í•´ë‹¹ í”½ì…€ì˜ ê¹Šì´ê°’ (0ì´ë©´ ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ê³  ë¬´ì‹œ)
        d = self.depth_image[v, u]
        if d > 0: return float(d)
        return None

    def image_callback(self, msg):
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            results = self.model(cv_image, verbose=False)
            
            detected_classes = []
            all_objects_data = [] 
            
            cv2.putText(cv_image, f"Target: {self.target_object}", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

            for r in results:
                if r.obb is not None:
                    for i, c in enumerate(r.obb.cls):
                        if r.obb.conf[i] < 0.6: continue

                        class_name = self.model.names[int(c)]
                        detected_classes.append(class_name)
                        
                        # OBB ê³„ì‚°
                        obb_box = r.obb.xywhr[i].cpu().numpy()
                        cx, cy = int(round(obb_box[0])), int(round(obb_box[1]))
                        w, h = obb_box[2], obb_box[3]
                        angle_rad = obb_box[4]

                        if w > h:
                            long_len, short_len = w, h
                            long_angle, short_angle = angle_rad, angle_rad + (math.pi / 2)
                        else:
                            long_len, short_len = h, w
                            long_angle, short_angle = angle_rad + (math.pi / 2), angle_rad

                        # 1. 5ê°œì˜ ì  ì¢Œí‘œ êµ¬í•˜ê¸° (ì¤‘ì‹¬, ê¸´ì¶• ì–‘ë, ì§§ì€ì¶• ì–‘ë)
                        l_p1, l_p2 = self.calculate_axis_points(cx, cy, long_len * 0.8, long_angle) # 0.8ì€ ëë¶€ë¶„ ë…¸ì´ì¦ˆ ë°©ì§€ìš© ì•ˆìª½
                        s_p1, s_p2 = self.calculate_axis_points(cx, cy, short_len * 0.8, short_angle)
                        
                        # (ì‹œê°í™”)
                        cv2.line(cv_image, l_p1, l_p2, (0, 0, 255), 2)
                        cv2.line(cv_image, s_p1, s_p2, (255, 0, 0), 2)
                        # 5ê°œ ì  ì°ì–´ë³´ê¸°
                        points_to_check = [(cx, cy), l_p1, l_p2, s_p1, s_p2]
                        for pt in points_to_check:
                            cv2.circle(cv_image, pt, 3, (0, 255, 255), -1)

                        # 2. 5ê°œ ì ì˜ Depth ìˆ˜ì§‘
                        valid_depths = []
                        for pt in points_to_check:
                            d = self.get_pixel_depth(pt[0], pt[1])
                            if d: valid_depths.append(d)
                        
                        if not valid_depths: continue # ê¹Šì´ ì •ë³´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ íŒ¨ìŠ¤

                        # 3. ì´ë²ˆ í”„ë ˆì„ì˜ í‰ê·  Depth (ê³µê°„ í‰ê· )
                        current_frame_avg_depth = np.mean(valid_depths)

                        # 4. 3í”„ë ˆì„ ë²„í¼ì— ì €ì¥ (ì‹œê°„ í‰ê· )
                        if class_name not in self.depth_buffers:
                            self.depth_buffers[class_name] = deque(maxlen=3)
                        
                        self.depth_buffers[class_name].append(current_frame_avg_depth)
                        
                        # 5. ìµœì¢… Depth ê³„ì‚° (ë²„í¼ ë‚´ í‰ê· )
                        final_stable_depth = np.mean(self.depth_buffers[class_name])
                        
                        # 6. 3D ì¢Œí‘œ ë³€í™˜ (Zê°’ì€ ìœ„ì—ì„œ êµ¬í•œ ì•ˆì •í™”ëœ ê°’ ì‚¬ìš©)
                        x_cam = (cx - self.cx) * final_stable_depth / self.fx
                        y_cam = (cy - self.cy) * final_stable_depth / self.fy
                        angle_deg = np.degrees(short_angle)
                        
                        # ìµœì¢… ì¢Œí‘œ: [x, y, stabilized_z, angle]
                        final_coords = [float(x_cam), float(y_cam), float(final_stable_depth), float(angle_deg)]

                        # ë°ì´í„° íŒ¨í‚¤ì§•
                        all_objects_data.append({
                            "name": class_name,
                            "coords": final_coords
                        })
                        
                        if self.target_object in class_name:
                            # ë””ë²„ê¹…: í™”ë©´ì— Depth í‘œì‹œ
                            cv2.putText(cv_image, f"Z: {int(final_stable_depth)}mm", (cx, cy+20), 
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                            
                            pos_msg = Float32MultiArray()
                            pos_msg.data = final_coords
                            self.pose_publisher.publish(pos_msg)

            if all_objects_data:
                json_msg = String()
                json_msg.data = json.dumps(all_objects_data)
                self.all_objects_publisher.publish(json_msg)

            self.result_publisher.publish(String(data=",".join(detected_classes)))
            cv2.imshow("YOLO Inference", cv_image) 
            cv2.waitKey(1)

        except Exception as e:
            self.get_logger().error(f'Processing Error: {e}')

def main(args=None):
    rclpy.init(args=args)
    node = YoloNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()